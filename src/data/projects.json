[
  {
    "id": 1,
    "title": "Screen View MCP",
    "description": "Using Anthropic's MCP SDK to enable AI assistants to capture and analyze screenshots using Claude Vision API.",
    "longDescription": "# Screen View MCP\n\nThis project implements a **Multi-Capability Platform (MCP)** integration that enables AI assistants to capture and analyze screenshots.\n\n## Features\n\n- Real-time screenshot capture\n- Integration with Claude Vision API for image analysis\n- Support for multiple screen resolutions\n- Cross-platform compatibility\n\n## Implementation Details\n\nThe project was built using:\n\n* TypeScript for type safety\n* Node.js for the backend\n* The Anthropic MCP SDK\n* Claude Vision API for image processing\n\n> This tool significantly enhances the capabilities of AI assistants, allowing them to directly observe and interact with what's on the user's screen.",
    "tags": ["TypeScript", "MCP SDK", "Claude Vision", "AI", "Node.js"],
    "imageUrl": "https://picsum.photos/seed/screen-view-mcp/600/400", 
    "images": [
      "https://picsum.photos/seed/screen-view-mcp-1/600/400",
      "https://picsum.photos/seed/screen-view-mcp-2/600/400"
    ],
    "sourceUrl": "https://github.com/hemenge133/screen-view-mcp",
    "liveUrl": null,
    "categories": ["Tooling", "AI/ML"]
  },
  {
    "id": 2,
    "title": "Latent",
    "description": "Research implementation exploring parameter efficiency and generalizability in transformers using latent space bottlenecks.",
    "longDescription": "# Latent Transformer for Multiplication\n\nThis project explores the impact of **latent bottlenecks** in transformer architectures on parameter efficiency and generalizability, using multiplication as the learning task.\n\n## Project Overview\n\nThe repository implements and compares two transformer variants:\n\n- **SimpleTransformer**: A standard transformer implementation\n- **LatentTransformer**: A modified architecture incorporating latent space bottlenecks\n\nThis project served as a personal learning experience to:\n\n1. Stay current with evolving transformer architectures in modern LLMs\n2. Experiment with transformer generalizability improvements\n3. Develop AI engineering skills with tools like Optuna for hyperparameter optimization\n\n## Technical Implementation\n\n### Technology Stack\n\n- **Framework**: PyTorch\n- **Optimization**: Optuna\n- **Data Processing**: NumPy, pandas\n- **Monitoring**: TensorBoard, tqdm\n- **Testing**: pytest\n\n### Architecture Features\n\n```python\n# Simple example of the latent space implementation\nclass LatentTransformer(nn.Module):\n    def __init__(self, d_model, num_layers, num_latent):\n        super().__init__()\n        # Compress to smaller latent dimensions\n        self.latent_size = num_latent\n        self.to_latent = nn.Linear(d_model, num_latent)\n        self.from_latent = nn.Linear(num_latent, d_model)\n```\n\nThe project includes comprehensive training infrastructure with hyperparameter optimization, checkpointing, and runtime metrics visualizationâ€”providing hands-on experience with modern AI engineering practices.",
    "tags": ["Python", "PyTorch", "AI/ML", "Research", "Transformers"],
    "imageUrl": "https://picsum.photos/seed/latent/600/400",
    "images": [
      "https://picsum.photos/seed/latent-1/600/400",
      "https://picsum.photos/seed/latent-2/600/400"
    ], 
    "sourceUrl": "https://github.com/hemenge133/latent",
    "liveUrl": null,
    "categories": ["AI/ML"]
  },
  {
    "id": 3,
    "title": "ConverseGPT",
    "description": "GPT-based chat app and infrastructure-as-code backend.",
    "longDescription": "# ConverseGPT\n\nA full-stack application featuring a React frontend and a Python backend powered by GPT models.\n\n## Architecture\n\n- **Frontend**: React with TypeScript\n- **Backend**: Python FastAPI\n- **Infrastructure**: AWS CDK (Infrastructure as Code)\n- **Database**: DynamoDB for conversation history\n- **Authentication**: Amazon Cognito\n\n## Key Features\n\n* Real-time chat with GPT models\n* Conversation history and context management\n* Multiple personality modes for different use cases\n* API throttling and cost management\n* Fully automated CI/CD pipeline\n\n> \"ConverseGPT offers enterprise-grade stability with consumer-friendly usability\" - *Tech Review Weekly*\n\nThe application was designed for scalability and reproducibility, with all infrastructure defined using AWS CDK.",
    "tags": ["Python", "React", "AWS", "IaC", "GPT", "Full-Stack"],
    "imageUrl": "https://picsum.photos/seed/converse-gpt/600/400",
    "images": [
        "https://picsum.photos/seed/converse-gpt-1/600/400",
        "https://picsum.photos/seed/converse-gpt-2/600/400"
    ],
    "sourceUrl": "https://github.com/hemenge133/converseGPT",
    "liveUrl": null,
    "categories": ["Web"]
  },
  {
    "id": 4,
    "title": "Orbital Portfolio",
    "description": "Interactive developer portfolio featuring a physics-based particle system.",
    "longDescription": "# Orbital Portfolio\n\nThis portfolio site combines **elegant UI design** with **interactive physics simulations** to create a unique user experience\n\n## Technical Architecture\n\n- **Framework**: Next.js 14 with App Router and React Server Components\n- **UI**: Tailwind CSS with shadcn/ui component system\n- **3D Rendering**: Three.js with custom GLSL shaders\n- **Animation**: Framer Motion for smooth UI transitions\n- **Theming**: Dynamic light/dark mode with responsive color palettes\n\n## Key Features\n\n### Particle Simulation \n\nThe centerpiece of the portfolio is a custom-built gravitational particle system that:\n\n* Creates thousands of particles that respond to simulated gravitational forces\n* Integrates with the user's cursor to allow interactive manipulation of the particle field\n* Dynamically adapts colors to match the current theme\n* Uses WebGL acceleration for smooth performance even on mobile devices\n\n### Advanced Rendering Techniques\n\n```typescript\nconst fragmentShader = `\n  uniform vec3 color;\n  uniform float opacity;\n  \n  void main() {\n    float distanceToCenter = length(gl_PointCoord - vec2(0.5));\n    float strength = 0.05 / distanceToCenter - 0.1;\n    gl_FragColor = vec4(color, strength * opacity);\n  }\n`;\n```\n\n### Accessibility & Performance Optimizations\n\n* Fully keyboard navigable for accessibility compliance\n* Conditional suspense boundaries for optimal loading\n* Edge-optimized static generation for near-instant page loads\n* Graceful degradation on devices without WebGL support\n\nThe project demonstrates how modern web technologies can create experiences that are both visually stunning and functionally accessible across all devices.",
    "tags": ["React", "Next.js", "Three.js", "TypeScript", "Tailwind CSS", "WebGL", "shadcn/ui", "Framer Motion"],
    "imageUrl": "https://picsum.photos/seed/orbital-portfolio/600/400",
    "images": [
        "https://picsum.photos/seed/orbital-portfolio-1/600/400",
        "https://picsum.photos/seed/orbital-portfolio-2/600/400"
    ],
    "sourceUrl": "https://github.com/hemenge133/shadcn-profile",
    "liveUrl": "https://haydenmenge.com",
    "categories": ["Web"]
  }
] 